{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'Colorado'\n",
    "\n",
    "# search settings\n",
    "area = False\n",
    "zip_code = False\n",
    "radius = False # can be 0, 5, 10, 25, 50, or 100\n",
    "state = 'CO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://forms.nabip.org/consumer/findagent2.cfm\" \n",
    "# options = webdriver.ChromeOptions() #newly added \n",
    "# options.headless = True #newly added \n",
    "# with webdriver.Chrome(options=options) as browser: #modified \n",
    "# \tbrowser.get(url)\n",
    "# \tprint(\"Page URL:\", browser.current_url) \n",
    "# \tprint(\"Page Title:\", browser.title)\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.get(url)\n",
    "\n",
    "\n",
    "# enter zip code\n",
    "if zip_code:\n",
    "    browser.find_element(By.XPATH, '/html/body/div/div[3]/form/table/tbody/tr[2]/td[2]/input').send_keys(zip_code)\n",
    "\n",
    "# enter radius\n",
    "if radius:\n",
    "    radius_select = Select(browser.find_element(By.XPATH, '/html/body/div/div[3]/form/table/tbody/tr[2]/td[2]/select'))\n",
    "    radius_select.select_by_visible_text('Single Zip Code') \n",
    "    radius_select.select_by_value(radius)\n",
    "\n",
    "if state:\n",
    "    state_select = Select(browser.find_element(By.XPATH, '/html/body/div/div[3]/form/table/tbody/tr[8]/td[2]/select'))\n",
    "    state_select.select_by_visible_text('Choose a State/Province') \n",
    "    state_select.select_by_value(state)\n",
    "\n",
    "\n",
    "# search database\n",
    "browser.find_element(By.XPATH, '/html/body/div/div[3]/form/table/tbody/tr[2]/td[2]/input').send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# find total num of brokers in area\n",
    "total_brokers = soup.find_all('p')\n",
    "\n",
    "# check there are results\n",
    "if len(total_brokers) == 1:\n",
    "    print(\"No members found\")\n",
    "    exit()\n",
    "\n",
    "total_brokers = int(total_brokers[1].text.split()[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brokers = []\n",
    "\n",
    "# loop until all brokers are found\n",
    "while len(brokers) < total_brokers:\n",
    "\n",
    "    # extract broker info\n",
    "    new_brokers = soup.find('div', {'class': 'contentContainer'})\n",
    "\n",
    "    new_brokers = new_brokers.find_all('div')\n",
    "\n",
    "    for broker in new_brokers:\n",
    "        data_dict = {'Name':'', 'Company':'', 'Website':'', 'Work Phone':'', 'Fax':'', 'Email':'', \\\n",
    "                    'Address':'', 'Zip Code':'', 'Certifications':'', 'Certified States':'', 'Practice Areas':''}\n",
    "\n",
    "        broker_text = broker.text.split('\\n')\n",
    "        broker_text = list(filter(None, broker_text))\n",
    "\n",
    "        # make sure its a full contact div\n",
    "        if len(broker_text) < 5:\n",
    "                continue\n",
    "        \n",
    "        broker_text.pop(0) # remove vCard item\n",
    "\n",
    "        # extract broker info to data_dict\n",
    "        for index, item in enumerate(broker_text):\n",
    "            if index == 0:\n",
    "                data_dict['Name'] = broker_text[index]\n",
    "            elif 'Certifications' in item:\n",
    "                data_dict['Certifications'] = broker_text[index]\n",
    "            elif 'Work Phone' in item:\n",
    "                temp_text = broker_text[index].split('Work Phone: ')[1]\n",
    "                if 'Fax' in temp_text:\n",
    "                    temp_text = temp_text.split(' Fax: ')\n",
    "                    data_dict['Work Phone'] = temp_text[0]\n",
    "                    data_dict['Fax'] = temp_text[1]\n",
    "                else:\n",
    "                    data_dict['Work Phone'] = temp_text\n",
    "            elif 'Chapter' in item:\n",
    "                data_dict['Certified States'] = broker_text[index].split('Chapter: ')[1]\n",
    "            elif 'Web Site' in item:\n",
    "                data_dict['Website'] = broker_text[index].split('Web Site: ')[1]\n",
    "            elif 'E-mail' in item:\n",
    "                temp_text = broker_text[index].split('E-mail: ')[1]\n",
    "                if 'Practice Areas' in temp_text:\n",
    "                    temp_text = temp_text.split(' Practice Areas: ')\n",
    "                    data_dict['Email'] = temp_text[0]\n",
    "                    data_dict['Practice Areas'] = temp_text[1]\n",
    "                else:\n",
    "                    data_dict['Email'] = temp_text\n",
    "                \n",
    "            else:\n",
    "                data_dict['Address'] = broker_text[index]\n",
    "                data_dict['Zip Code'] = broker_text[index].split(' ')[-1]\n",
    "                \n",
    "                # get company from address\n",
    "                split = broker_text[index].split()\n",
    "                curr_string = ''\n",
    "                for string in split:\n",
    "                    if string.isnumeric():\n",
    "                        break\n",
    "                    elif string == \"PO\":\n",
    "                        break\n",
    "                    curr_string += string + ' '\n",
    "                \n",
    "                data_dict['Company'] = curr_string\n",
    "\n",
    "\n",
    "        # only add broker if not already in list\n",
    "        if data_dict not in brokers:\n",
    "            brokers.append(data_dict)\n",
    "\n",
    "\n",
    "    print(f'Found {len(brokers)}/{total_brokers} brokers')\n",
    "\n",
    "    # reload page & create new BS object after all processing\n",
    "    browser.find_element(By.CLASS_NAME, 'bluebutton').send_keys(Keys.ENTER)\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "browser.close()\n",
    "print(f'Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dictionary into DataFrame and export to csv\n",
    "\n",
    "brokers_final = pd.DataFrame(brokers)\n",
    "\n",
    "brokers_final.to_csv(f'Output\\\\{database_name}_brokers.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
